{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_info(path):\n",
    "    \"\"\"get basic information about the dataset\n",
    "    input: path of the json to load\n",
    "    output: df, df.info(), df.head(), df.describe(): dataset and its summmary statistics with a sample data\"\"\"\n",
    "    df = pd.read_json(path, orient='records', lines=True)\n",
    "    return df, df.info(), df.head(), df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_multiindex_colnames(df):\n",
    "    \"\"\"flattens the multi index column names and assign them to the new dataframe\n",
    "    \"\"\"\n",
    "    df.columns = (['_'.join(col).strip() for col in df.columns.values])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_success_flag_cust_offer_disc_bogo(offers_master):\n",
    "    \"\"\"\n",
    "     customer offer is mentioned as successful if the offer was viewed before completed \n",
    "     or in the few (533) scenarios where customer has consumed 2 offers in one go it is assumed they are offer success pplas they have known that they had 2 offers\n",
    "    input: offers dataframe with custimer, offerid, event, time, portfolio data\n",
    "    output: get a pandas dataframe with customer, offer and success flag - only the successful customers\n",
    "    \"\"\"\n",
    "    # add time columns\n",
    "    offers_master['time'] = offers_master['time'] + 0.1 # adding 0.1 time as offer time is mentioned as 0\n",
    "    offers_master['received_time'] = offers_master['offer_received'] * offers_master['time']\n",
    "    offers_master['viewed_time'] = offers_master['offer_viewed'] * offers_master['time']\n",
    "    offers_master['completed_time'] = offers_master['offer_completed'] * offers_master['time']\n",
    "    \n",
    "    cust_offers = offers_master[[\"cust_id\", \"offer_id\", \"event\", \"time\", \"completed_time\", \"received_time\", \"viewed_time\", \"offer_type\"]]\n",
    "\n",
    "    cust_offers['lagged_event'] = (cust_offers\n",
    "                       .sort_values(by=['time'], ascending=True)\n",
    "                       .groupby([\"cust_id\", \"offer_id\"])[\"event\"].shift(1))\n",
    "    cust_offers['lagged_viewed_time'] = (cust_offers\n",
    "                       .sort_values(by=['time'], ascending=True)\n",
    "                       .groupby([\"cust_id\", \"offer_id\"])[\"viewed_time\"].shift(1))\n",
    "    cust_offers['lagged_event_2'] = (cust_offers\n",
    "                       .sort_values(by=['time'], ascending=True)\n",
    "                       .groupby([\"cust_id\", \"offer_id\"])[\"event\"].shift(2))\n",
    "    cust_offers['lagged_event_3'] = (cust_offers\n",
    "                       .sort_values(by=['time'], ascending=True)\n",
    "                       .groupby([\"cust_id\", \"offer_id\"])[\"event\"].shift(3))\n",
    "    cust_offers['lagged_received_time'] = (cust_offers\n",
    "                       .sort_values(by=['time'], ascending=True)\n",
    "                       .groupby([\"cust_id\", \"offer_id\"])[\"received_time\"].shift(2))\n",
    "    cust_offers_completed = cust_offers[cust_offers['event']=='offer completed']\n",
    "\n",
    "    cust_offers_completed_bogo_disc = cust_offers_completed[cust_offers_completed['offer_type']!='informational']\n",
    "\n",
    "    cust_offers_completed_bogo_disc['cust_offer_success_bogo_disc'] = (np.where(\n",
    "                                                                        (\n",
    "                                                                            (\n",
    "                                                                                (cust_offers_completed_bogo_disc['lagged_event'] == 'offer viewed')\n",
    "                                                                                & \n",
    "                                                                                (cust_offers_completed_bogo_disc['lagged_event_2'] == 'offer received')\n",
    "                                                                            )\n",
    "                                                                            |\n",
    "                                                                            (\n",
    "                                                                                cust_offers_completed_bogo_disc['lagged_event'] == 'offer completed'\n",
    "                                                                            )\n",
    "\n",
    "                                                                        ),\n",
    "                                                                     1, 0)\n",
    "                                                             )\n",
    "\n",
    "    cust_success_bogo_disc = (cust_offers_completed_bogo_disc\n",
    "                                       .groupby([\"cust_id\", \"offer_id\"])\n",
    "                                      .max()['cust_offer_success_bogo_disc']).reset_index()\n",
    "\n",
    "    cust_success_bogo_disc = cust_success_bogo_disc[cust_success_bogo_disc['cust_offer_success_bogo_disc']==1]\n",
    "    return cust_success_bogo_disc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_informational_success(offers, transcript):\n",
    "    \"\"\"caclculate the offer success for informational offers\n",
    "    success has been calculated if the customer has been received, viewed and \n",
    "    transaction happened one after the other\"\"\"\n",
    "    # informational offers customers\n",
    "    transcript_info = transcript.copy(deep = True)\n",
    "    transcript_info['offer_id'] =  transcript_info['value'].apply(lambda x: list(x.values())[0])\n",
    "    transcript_info = transcript_info.merge(portfolio[['offer_id', 'offer_type']], on = 'offer_id', how = 'left')\n",
    "    \n",
    "    # get the customers who have received atleast one informational offers\n",
    "    info_offers = offers[offers['offer_type']=='informational']\n",
    "    info_offers_cust = info_offers[['cust_id']].drop_duplicates()\n",
    "    duration = offers[offers['offer_type']=='informational'][['offer_id', 'duration']].drop_duplicates()\n",
    "\n",
    "    trx_info = (transcript_info\n",
    "        .merge(info_offers_cust, on = 'cust_id')\n",
    "           .merge(duration, on = 'offer_id', how = 'left')\n",
    "           .fillna(0))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # remove other offers except informational ones\n",
    "    trx_info = (trx_info[~((trx_info['offer_type'] == 'bogo')\n",
    "                        |(trx_info['offer_type'] == 'discount')) ])\n",
    "\n",
    "    trx_info['next_event'] = (trx_info\n",
    "                       .sort_values(by=['time'], ascending=True)\n",
    "                       .groupby([\"cust_id\"])[\"event\"].shift(-1))\n",
    "\n",
    "    trx_info['next_event_2'] = (trx_info\n",
    "                       .sort_values(by=['time'], ascending=True)\n",
    "                       .groupby([\"cust_id\"])[\"event\"].shift(-2))\n",
    "    \n",
    "    trx_info['next_event_time_2'] = (trx_info\n",
    "                   .sort_values(by=['time'], ascending=True)\n",
    "                   .groupby([\"cust_id\"])[\"time\"].shift(-2))\n",
    "    \n",
    "    trx_info['time_diff'] = trx_info['next_event_time_2'] - trx_info['time']\n",
    "\n",
    "    trx_info['cust_offer_success_info'] = (np.where(\n",
    "                                                        (\n",
    "                                                            (   (trx_info['event'] == 'offer received')\n",
    "                                                             & \n",
    "                                                                (trx_info['next_event'] == 'offer viewed')\n",
    "                                                                & \n",
    "                                                                (trx_info['next_event_2'] == 'transaction')\n",
    "                                                              & \n",
    "                                                                (trx_info['time_diff'] <= trx_info['duration'])\n",
    "                                                            )\n",
    "\n",
    "\n",
    "                                                        ),\n",
    "                                                     1, 0)\n",
    "                                             )\n",
    "\n",
    "    trx_info_success = (trx_info\n",
    "                                       .groupby([\"cust_id\", \"offer_id\"])\n",
    "                                      .max()['cust_offer_success_info']).reset_index()\n",
    "\n",
    "    trx_info_success = trx_info_success[trx_info_success['cust_offer_success_info']==1]\n",
    "    return trx_info_success\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box_plots_bi_level_multiple(df, y_var, x_var, hue_var, query_var, axes, title_var):\n",
    "    \"\"\"get groupwise(x) boxplots for y variables with dataframe filtered\n",
    "    input:df: pandas dataframe\n",
    "           y_var: string column name of variable to plot\n",
    "           x_var: string column name to grop var\n",
    "           hue_var: string col name to go in the legend\n",
    "           query_var: string with the query ex: ('colname>0')\n",
    "           title_var: title as a string\n",
    "           axes: position as ax[0], ax[1]\n",
    "    output: return boxplots as charts\n",
    "    \"\"\"\n",
    "    \n",
    "    ax = sns.boxplot(data = df.query(query_var),\n",
    "        x = x_var,\n",
    "               y = y_var,\n",
    "               showfliers = False,\n",
    "               hue=hue_var\n",
    "                , ax = axes\n",
    "               )\n",
    "    ax.set(title=title_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corrleation_plot(features, ant):\n",
    "    \"\"\"input: features-pandas dataframe with features to plot\n",
    "            ant - True means to annotate\n",
    "    output: plot the correlations\"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    sns.set(font_scale=1.5)\n",
    "    sns.heatmap(features.corr(),\n",
    "            annot = ant,\n",
    "            fmt = '.2f',\n",
    "            linewidths=.8,\n",
    "            cmap='YlGnBu')\n",
    "\n",
    "    plt.title('Correlation between features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_split(x,y):\n",
    "    '''\n",
    "    split the features and target into train and test set and scale the datasets\n",
    "    input: x : pandas dataframe with set of features\n",
    "            y : pandas dataframe with the target\n",
    "    output: X_train : scaled x train values as a numpy ndarray\n",
    "            X_test : scaled x test values as a numpy ndarray\n",
    "            y_train : pandas series\n",
    "            y_test : pandas series\n",
    "\n",
    "    '''\n",
    "    \n",
    "    #split into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x,\n",
    "                                                        y, \n",
    "                                                        test_size=0.20, \n",
    "                                                        random_state=42)\n",
    "\n",
    "    #fit and transform scaling on training data\n",
    "    scaler=StandardScaler()\n",
    "    X_train=scaler.fit_transform(X_train)\n",
    "\n",
    "    #scale test data\n",
    "    X_test=scaler.transform(X_test)\n",
    "    \n",
    "    return X_train,X_test,y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importance(model, features, plot= True):\n",
    "    \"\"\"get feature importance as a pandas dataframe given the classifer and if plot is True provide a bar chart\"\"\"\n",
    "    feature_importances = pd.DataFrame(model.feature_importances_,\n",
    "                                   index = features.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "    \n",
    "    feature_importances = feature_importances[feature_importances['importance']>0]\n",
    "    if plot:\n",
    "        feature_importances.plot.bar()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_models_v2(clf_list, X_train, y_train, X_test, y_test, master_name, print_res = True):\n",
    "    '''\n",
    "    inputs:\n",
    "    - clf_list: list of classifiers\n",
    "    -X_train, y_train, X_test, y_test: train test splitted datasets\n",
    "    outputs:\n",
    "    - Dataframe of results from model training and prediction\n",
    "    '''\n",
    "    \n",
    "    results = {}\n",
    "    for clf in clf_list:\n",
    "        clf_name = clf.__class__.__name__\n",
    "        results[clf_name] = {}\n",
    "        results[clf_name]= predict_evaluate_model_v2(clf, X_train, y_train, X_test, y_test, master_name, True, print_res)\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_evaluate_model_v2(model, X_train, y_train, X_test, y_test, dataframe_name, as_list = True, print_res = True): \n",
    "    '''\n",
    "    generate predictions using a given model and return the results\n",
    "    input: model: classifier\n",
    "          X_train, y_train, X_test, y_test: master splitted to x and y and train, test\n",
    "          dataframe_name : master name as a string\n",
    "          as_list: if True output as a list else as a dataframe\n",
    "    output: results as a dictionary\n",
    "    '''\n",
    "    results = {}\n",
    "    \n",
    "    #Fit the learner to the training data and get training time\n",
    "    model = model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predictions on the test set(X_test)\n",
    "    predictions_test = model.predict(X_test)\n",
    "    predictions_train = model.predict(X_train)\n",
    "    \n",
    "    \n",
    "    results['dataframe_name'] = [dataframe_name]\n",
    "    \n",
    "    #add training accuracy to results\n",
    "    results['training_score']=model.score(X_train,y_train)\n",
    "    \n",
    "    #add testing accuracy to results\n",
    "    results['testing_score']=model.score(X_test,y_test)\n",
    "    \n",
    "    \n",
    "    precision_te, recall_te, fscore_te, support_te = score(y_test, predictions_test)\n",
    "    precision_tr, recall_tr, fscore_tr, support_tr = score(y_train, predictions_train)\n",
    "    \n",
    "#     results['training_precion_class0'] = precision_tr[0]\n",
    "#     results['testing_precion_class0'] = precision_te[0]\n",
    "#     results['training_recall_class_0'] = recall_tr[0]\n",
    "#     results['testing_recall_class_0'] = recall_te[0]\n",
    "    results['training_fscore_class_0'] = fscore_tr[0]\n",
    "    results['testing_fscore_class_0'] = fscore_te[0]\n",
    "    results['training_fscore_class_1'] = fscore_tr[1]\n",
    "    results['testing_fscore_class_1'] = fscore_te[1]\n",
    "#     results['training_support_class_0'] = support_tr[0]\n",
    "#     results['testing_support_class_0'] = support_te[0]\n",
    "    \n",
    "    if print_res:\n",
    "     \n",
    "        print(\"{} trained on {} samples.\".format(model.__class__.__name__, len(y_train)))\n",
    "        print(\"MSE_train: %.4f\" % mean_squared_error(y_train,predictions_train))\n",
    "        print(\"MSE_test: %.4f\" % mean_squared_error(y_test,predictions_test))\n",
    "        print(\"Training accuracy: %.4f\" % results['training_score'])\n",
    "        print(\"Test accuracy: %.4f\" % results['testing_score'])\n",
    "        print(classification_report(y_test, predictions_test,digits=4))\n",
    "        \n",
    "\n",
    "        cm = confusion_matrix(y_test, predictions_test)\n",
    "        confusion = sns.heatmap(cm, annot=True, fmt='g')\n",
    "        \n",
    "        \n",
    "    \n",
    "    if as_list:\n",
    "        return (results)\n",
    "    else:\n",
    "        return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(master, x_col_list, y_col_name):\n",
    "    \"\"\"split the master to x and y sets\"\"\"\n",
    "    y = master[[y_col_name]]\n",
    "    x = master[x_col_list]\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_imbalance_methods(master, model, x_var, y_var):\n",
    "    \"\"\"input: master: pandas dataframe\n",
    "                model: classifier\n",
    "                features_to_drop: feature list to drop\n",
    "    \n",
    "    output: pandas dataframe with accuracy across different methods\n",
    "    \"\"\"\n",
    "    df_minority = master[master['tot_success']==0]\n",
    "    df_majority = master[master['tot_success']==1]\n",
    "\n",
    "    # oversampling\n",
    "    df_minority_oversampled = resample(df_minority, replace=True, n_samples=10016, random_state=0)\n",
    "    df_oversampled = pd.concat([df_majority, df_minority_oversampled])\n",
    "\n",
    "    # undersampling\n",
    "    df_majority_undersampled = resample(df_majority, replace=True, n_samples=4809, random_state=0)\n",
    "    df_undersampled = pd.concat([df_majority_undersampled, df_minority])\n",
    "\n",
    "    rus = RandomUnderSampler()\n",
    "    ros = RandomOverSampler()\n",
    "    cc = ClusterCentroids(sampling_strategy={0: 10})\n",
    "    smote = SMOTE(sampling_strategy='minority')\n",
    "    \n",
    "    \n",
    "    x, y = get_x_y(df_oversampled, x_var, y_var)\n",
    "    X_train, X_test, y_train, y_test = get_train_test_split(x,y)\n",
    "    df2 = predict_evaluate_model_v2(model, X_train, y_train, X_test, y_test, 'df_oversampled', as_list = False, print_res = False)\n",
    "    \n",
    "    x, y = get_x_y(df_undersampled, x_var, y_var)\n",
    "    X_train,X_test,y_train, y_test = get_train_test_split(x,y)\n",
    "    df3 = predict_evaluate_model_v2(model, X_train, y_train, X_test, y_test, 'df_undersampled', as_list = False, print_res = False)\n",
    "\n",
    "    x, y = get_x_y(master, x_var, y_var)\n",
    "    X_train, X_test, y_train, y_test = get_train_test_split(x,y)\n",
    "    df1 = predict_evaluate_model_v2(model, X_train, y_train, X_test, y_test, 'master', as_list = False, print_res = False)\n",
    "\n",
    "    X_train_rus, y_train_rus = rus.fit_resample(X_train, y_train)\n",
    "    df_rus = predict_evaluate_model_v2(model, X_train_rus, y_train_rus, X_test, y_test, 'RUS', as_list = False, print_res = False)\n",
    "\n",
    "    X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)\n",
    "    df_ros = predict_evaluate_model_v2(model, X_train_ros, y_train_ros, X_test, y_test, 'ROS', as_list = False, print_res = False)\n",
    "\n",
    "    X_train_cc, y_train_cc= cc.fit_resample(X_train, y_train)\n",
    "    df_cc = predict_evaluate_model_v2(model, X_train_cc, y_train_cc, X_test, y_test, 'cc', as_list = False, print_res = False)\n",
    "\n",
    "    X_train_smote, y_train_smote = ros.fit_resample(X_train, y_train)\n",
    "    df_smote = predict_evaluate_model_v2(model, X_train_smote, y_train_smote , X_test, y_test, 'SMOTE', as_list = False, print_res = False)\n",
    "\n",
    "\n",
    "    concat_results = pd.concat([df1, df2, df3, df_rus, df_ros, df_cc, df_smote])\n",
    "    return concat_results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_barplots_for_gender_success(df, i, title_str):\n",
    "    \"\"\"df : pandas dataframe \n",
    "       i : axis position\n",
    "       title_str : string with title\n",
    "       return: count plots with x : gender, y : success flag count\n",
    "    \n",
    "    \"\"\"\n",
    "    ax = sns.barplot('gender',\n",
    "                     y='sucess_flag_bogo', \n",
    "                     data=df.query('event_count_bogo >0'), \n",
    "                     ci=None,\n",
    "                     order=[\"M\", \"F\", \"O\"],\n",
    "                    ax=axs[i, 0])\n",
    "    ax.set(title='BOGO: ' + title_str)\n",
    "    ax = sns.barplot('gender', \n",
    "                     y='sucess_flag_discount', \n",
    "                     data=df.query('event_count_discount >0'), \n",
    "                     ci=None,\n",
    "                     order=[\"M\", \"F\", \"O\"],\n",
    "                    ax=axs[i, 1])\n",
    "    ax.set(title='Discount: '+ title_str)\n",
    "    ax = sns.barplot('gender',\n",
    "                     y='sucess_flag_informational', \n",
    "                     data=df.query('event_count_informational >0'), \n",
    "                     ci=None,\n",
    "                     order=[\"M\", \"F\", \"O\"],\n",
    "                    ax=axs[i, 2])\n",
    "    ax.set(title='Informational: ' + title_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(results):\n",
    "    \"\"\"display the results of the model\"\"\"\n",
    "    print(f'Best parameters are: {results.best_params_}')\n",
    "    print(\"\\n\")\n",
    "    mean_score = results.cv_results_['mean_test_score']\n",
    "    std_score = results.cv_results_['std_test_score']\n",
    "    params = results.cv_results_['params']\n",
    "    for mean,std,params in zip(mean_score,std_score,params):\n",
    "        print(f'{round(mean,3)} + or -{round(std,3)} for the {params}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
